<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prof. Shlomo Hareli - Datasets</title>
    <link rel="stylesheet" href="style.css">
    <style>
        .dropdown {
            position: relative;
            display: inline-block;
        }
        .dropdown-content {
            display: none;
            position: absolute;
            background-color: #f9f9f9;
            min-width: 200px;
            box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
            padding: 12px 16px;
            z-index: 1;
            border-radius: 5px;
            top: 100%;
            left: 0;
        }
        .dropdown:hover .dropdown-content {
            display: block;
        }
        .dropdown-content a {
            color: #67B8E3;
            padding: 12px 16px;
            text-decoration: none;
            display: block;
            border-radius: 3px;
        }
        .dropdown-content a:hover {
            background-color: #f0e6ff;
            color: #4A90E2;
        }
        nav li.dropdown > a:after {
            content: " ▼";
            font-size: 0.8rem;
        }
            nav li.dropdown > button {
            background: none;
            border: none;
            color: inherit;
            font: inherit;
            cursor: pointer;
            padding: 0;
        }
        nav li.dropdown > button:after {
            content: " ▼";
            font-size: 0.8rem;
        }
    </style>
</head>
<body>
    <header>
        <div class="header-content">
            <h1>Prof. Shlomo Hareli</h1>
            <p>Social Psychologist | University of Haifa</p>
        </div>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="research.html">Research</a></li>
                <li><a href="students.html">Students</a></li>
                <li><a href="teaching.html">Teaching</a></li>
                <li><a href="datasets.html">Datasets</a></li>
                <li><a href="contact.html">Contact</a></li>
                <li><a href="links.html">Links</a></li>
                
                <li class="dropdown">
                    <button aria-label="More pages menu" aria-expanded="false" aria-haspopup="true">More</button>
                    <div class="dropdown-content" role="menu">
                        <a href="news.html" role="menuitem">In the News and on the Web</a>
                        <a href="posters.html" role="menuitem">Posters at Conferences</a>
                        <a href="presentations.html" role="menuitem">Invited Presentations</a>
                        <a href="facebook.html" role="menuitem">My Facebook Group</a>
                        <a href="accessibility.html" role="menuitem">Accessibility Statement</a>
                    </div>
                </li>
            </ul>
        </nav>
    </header>

    <div class="container">
        <main>
            <h1>Research Datasets</h1>

            <section>
                <h2>Haifa Set of Facial Expressions of Emotions (HSFEE)</h2>

                <div class="dataset-card">
                    <h3>Overview</h3>
                    <p>HSFEE (Haifa Set of Facial Expressions of Emotions) consists of emotional facial expressions by 3 Israeli men and 3 Israeli women. Each expression was created by instructing actors to show the respective expression. The set was created by Dr. Shimon Elkabetz in collaboration with Prof. Shlomo Hareli and Prof. Ursula Hess.</p>

                    <p>Expressions were validated in a study using them (Hareli, Elkabetz, & Hess, 2019). The set contains expressions of happiness, awe, surprise and neutrality for each actor. Photos were taken against a green screen background to enable electronic manipulation of background context.</p>
                </div>

                <h3>Terms of Use</h3>
                <div class="dataset-card">
                    <p>The Haifa Set of Facial Expressions of Emotions and stimuli are to be used <strong>without charge for non-commercial research purposes only</strong>. All and any (re-)distribution and publishing without the written consent of the copyright holders is forbidden.</p>

                    <p><strong>Copyright holder:</strong> Laboratory for the Study of Social Perception of Emotions, the University of Haifa, Haifa Israel.</p>

                    <p>In order to use the stimuli for purposes of illustration in conferences or manuscripts, consent from the authors of the HSFEE must be obtained. Please contact Prof. Hareli Shlomo at: <strong><a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="74071c150611181d34011a1d025a1c151d12155a15175a1d18">[email&#160;protected]</a></strong></p>

                    <p><strong>Required Attribution:</strong> The creators of the set, Dr. Shimon Elkabetz, Prof. Ursula Hess and Prof. Shlomo Hareli, should be acknowledged in any manuscript originating from projects using the stimulus set via the following reference:</p>

                    <p style="margin-left: 2rem; font-style: italic;">Hareli, S., Elkabetz, S., & Hess, U. (2019). Drawing inferences from emotion expressions: The role of situative informativeness and context. <em>Emotion</em>, 19, 200-208. doi: 10.1037/emo0000368</p>

                    <p>One electronic copy of any manuscript resulting from use of the HSFEE stimulus set should be sent to Prof. Hareli Shlomo at: <strong><a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="f88b90998a9d9491b88d96918ed69099919e99d6999bd69194">[email&#160;protected]</a></strong></p>
                </div>

                <h3>Data Security</h3>
                <div class="dataset-card">
                    <p>In order to download the HSFEE, you will be asked for your name, institutional affiliation, and your email address. This data will be saved and is necessary in order to contact you and to send you a download link to the HSFEE. The data will not be used for any other purpose.</p>

                    <p>If you do not complete the download form, no data will be saved.</p>

                    <p>By marking the "Terms of use" below, you signal your agreement with this use of your data.</p>

                    <p><a href="https://sites.google.com/view/prof-shlomo-hareli/haifa-set-of-facial-expressions-of-emotions" target="_blank" class="btn">Request HSFEE Dataset Access</a></p>
                    <p style="font-size: 0.9rem; color: #555;"><em>Note: You will be redirected to a form where you can request access to the dataset.</em></p>
                </div>
            </section>

            <section>
                <h2>Body Weight and Expressions of Emotions - AI-Generated Images Datasets</h2>

                <div class="dataset-card">
                    <h3>Version 1</h3>
                    <p>This dataset includes <strong>72 high-quality images</strong> of individuals from the chest up, generated using ComfyUI and enhanced with the fluxi-dev model. The images represent diverse body types (fit, middleweight, obese) and emotional expressions (happiness, sadness, neutrality) across genders.</p>

                    <p>Each image was meticulously analyzed and edited to ensure an accurate representation of emotions, with a <strong>validation criterion of at least 95% likelihood of the desired emotion</strong>. The final dataset features images of four different men and women, each expressing the specified emotions.</p>

                    <p>Additionally, it includes the results of an analysis using Py-Feat, detailing the likelihood of the emotion shown and the specific Action Units (AUs) detected.</p>

                    <p><a href="https://drive.google.com/drive/folders/1Rg3NzdbkGGvcZoNGEhnz0SM0Jt9Xp-lA?usp=sharing" target="_blank" class="btn">Access Version 1 Dataset</a></p>
                </div>

                <div class="dataset-card">
                    <h3>Version 2</h3>
                    <p>This dataset includes <strong>96 high-quality images</strong> of individuals from the chest up, generated using ComfyUI and enhanced with the fluxi-dev model. The images represent diverse body types (fit, middleweight, obese) and emotional expressions (happiness, sadness, anger, and neutrality) across genders.</p>

                    <p>Each image was meticulously analyzed and edited to ensure an accurate representation of emotions, with a <strong>validation criterion of at least 95% likelihood of the desired emotion</strong>. The final dataset features images of four different men and women, each expressing all four emotions.</p>

                    <p>Additionally, it includes the results of an analysis using Py-Feat, detailing the likelihood of the emotion shown and the specific Action Units (AUs) detected.</p>

                    <p><a href="https://drive.google.com/drive/folders/1t6pT5mlwFEa_WYz8ayxDuCNqSZWIlrd3?usp=sharing" target="_blank" class="btn">Access Version 2 Dataset</a></p>
                </div>

                <h3>Dataset Features</h3>
                <ul>
                    <li><strong>High Resolution Images:</strong> Professional quality images suitable for research and publication</li>
                    <li><strong>Diverse Body Types:</strong> Representation of fit, middleweight, and obese body compositions</li>
                    <li><strong>Multiple Emotional Expressions:</strong> Comprehensive coverage of key emotional states</li>
                    <li><strong>Gender Diversity:</strong> Both male and female participants represented equally</li>
                    <li><strong>Validated Emotions:</strong> All images meet 95% validation threshold for emotion accuracy</li>
                    <li><strong>Action Unit Analysis:</strong> Detailed Py-Feat analysis of facial action units for scientific validation</li>
                    <li><strong>AI-Generated:</strong> Created using advanced AI models (ComfyUI with fluxi-dev) for consistency and quality</li>
                </ul>
            </section>

            <section>
                <h2>Using These Datasets</h2>
                <div class="highlight">
                    <p>These datasets are valuable research resources for studying the relationship between emotional expressions, body characteristics, and social perception. They can be used for:</p>
                    <ul>
                        <li>Understanding how body weight influences perception of emotions</li>
                        <li>Investigating the relationship between body type and attribution of personality traits</li>
                        <li>Developing and testing emotion recognition algorithms</li>
                        <li>Cross-cultural emotion perception studies</li>
                        <li>Training machine learning models for emotion detection</li>
                    </ul>
                </div>
            </section>
        </main>
    </div>

    <fo